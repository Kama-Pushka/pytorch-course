# Домашнее задание к уроку 1: Основы PyTorch

## Цель задания
Закрепить навыки работы с тензорами PyTorch, изучить основные операции и научиться решать практические задачи.

## Задание 1: Создание и манипуляции с тензорами (25 баллов)

Создайте файл `homework_tensors.py` и выполните следующие задачи:

### 1.1 Создание тензоров (7 баллов)

Создайте следующие тензоры:
 - [x] Тензор размером 3x4, заполненный случайными числами от 0 до 1
 - [x] Тензор размером 2x3x4, заполненный нулями
 - [x] Тензор размером 5x5, заполненный единицами
 - [x] Тензор размером 4x4 с числами от 0 до 15 (используйте reshape)

### 1.2 Операции с тензорами (6 баллов)

Дано: тензор A размером 3x4 и тензор B размером 4x3
Выполните:
- [x] Транспонирование тензора A
- [x] Матричное умножение A и B
- [x] Поэлементное умножение A и транспонированного B
- [x] Вычислите сумму всех элементов тензора A


### 1.3 Индексация и срезы (6 баллов)

Создайте тензор размером 5x5x5
Извлеките:
- [x] Первую строку
- [x] Последний столбец
- [x] Подматрицу размером 2x2 из центра тензора
- [x] Все элементы с четными индексами


### 1.4 Работа с формами (6 баллов)

Создайте тензор размером 24 элемента
Преобразуйте его в формы:
- [x] 2x12
- [x] 3x8
- [x] 4x6
- [x] 2x3x4
- [x] 2x2x2x3


## Задание 2: Автоматическое дифференцирование (25 баллов)

Создайте файл `homework_autograd.py`:

### 2.1 Простые вычисления с градиентами (8 баллов)

- [x] Создайте тензоры x, y, z с requires_grad=True
- [x] Вычислите функцию: f(x,y,z) = x^2 + y^2 + z^2 + 2*x*y*z
- [x] Найдите градиенты по всем переменным
- [x] Проверьте результат аналитически


### 2.2 Градиент функции потерь (9 баллов)

Реализуйте функцию MSE (Mean Squared Error):
- [x] MSE = (1/n) * Σ(y_pred - y_true)^2
- [x] где y_pred = w * x + b (линейная функция)
- [x] Найдите градиенты по w и b


### 2.3 Цепное правило (8 баллов)

- [x] Реализуйте составную функцию: f(x) = sin(x^2 + 1)
- [x] Найдите градиент df/dx
- [x] Проверьте результат с помощью torch.autograd.grad


## Задание 3: Сравнение производительности CPU vs CUDA (20 баллов)

Создайте файл `homework_performance.py`:

### 3.1 Подготовка данных (5 баллов)

Создайте большие матрицы размеров:
- [x] 64 x 1024 x 1024
- [x] 128 x 512 x 512
- [x] 256 x 256 x 256
- [x] Заполните их случайными числами


### 3.2 Функция измерения времени (5 баллов)

- [x] Создайте функцию для измерения времени выполнения операций
- Используйте torch.cuda.Event() для точного измерения на GPU
- Используйте time.time() для измерения на CPU


### 3.3 Сравнение операций (10 баллов)

Сравните время выполнения следующих операций на CPU и CUDA:
- [x] Матричное умножение (torch.matmul)
- [x] Поэлементное сложение
- [x] Поэлементное умножение
- [x] Транспонирование
- [x] Вычисление суммы всех элементов

```python
# Для каждой операции:
# 1. Измерьте время на CPU
# 2. Измерьте время на GPU (если доступен)
# 3. Вычислите ускорение (speedup)
# 4. Выведите результаты в табличном виде
```
### Таблица вывода:
```
+------------------------+------------------+------------+------------+-------------+
| Операция               | Размер           |   CPU (мс) |   GPU (мс) | Ускорение   |
+========================+==================+============+============+=============+
| Матричное умножение    | (64, 1024, 1024) |    294.935 |    661.544 | 0.45x       |
+------------------------+------------------+------------+------------+-------------+
| Матричное умножение    | (128, 512, 512)  |     82.097 |      3.827 | 21.45x      |
+------------------------+------------------+------------+------------+-------------+
| Матричное умножение    | (256, 256, 256)  |     19.995 |      1.002 | 19.95x      |
+------------------------+------------------+------------+------------+-------------+
| Поэлементное сложение  | (64, 1024, 1024) |     27.002 |      2.347 | 11.5x       |
+------------------------+------------------+------------+------------+-------------+
| Поэлементное сложение  | (128, 512, 512)  |      8.013 |      1.194 | 6.71x       |
+------------------------+------------------+------------+------------+-------------+
| Поэлементное сложение  | (256, 256, 256)  |      3.937 |      0.601 | 6.55x       |
+------------------------+------------------+------------+------------+-------------+
| Поэлементное умножение | (64, 1024, 1024) |     14.954 |      2.376 | 6.29x       |
+------------------------+------------------+------------+------------+-------------+
| Поэлементное умножение | (128, 512, 512)  |      6.99  |      1.192 | 5.86x       |
+------------------------+------------------+------------+------------+-------------+
| Поэлементное умножение | (256, 256, 256)  |      3.999 |      0.595 | 6.72x       |
+------------------------+------------------+------------+------------+-------------+
| Транспонирование       | (64, 1024, 1024) |      0     |      0.001 | 0.0x        |
+------------------------+------------------+------------+------------+-------------+
| Транспонирование       | (128, 512, 512)  |      0     |      0.001 | 0.0x        |
+------------------------+------------------+------------+------------+-------------+
| Транспонирование       | (256, 256, 256)  |      0     |      0.001 | 0.0x        |
+------------------------+------------------+------------+------------+-------------+
| Сумма всех элементов   | (64, 1024, 1024) |      5.939 |      1.086 | 5.47x       |
+------------------------+------------------+------------+------------+-------------+
| Сумма всех элементов   | (128, 512, 512)  |      2.966 |      0.543 | 5.47x       |
+------------------------+------------------+------------+------------+-------------+
| Сумма всех элементов   | (256, 256, 256)  |      1.94  |      0.275 | 7.04x       |
+------------------------+------------------+------------+------------+-------------+
```

### 3.4 Анализ результатов (5 баллов)

Проанализируйте результаты:
- Какие операции получают наибольшее ускорение на GPU?
  ```
  Практически все операции получили значительное ускорение, кроме матричного умножения первой матрицы (64, 1024, 1024).
  Замедление в данном случае происходит из-за того, что эта операция происходит самой первой
  и вместе с ней выполняются подготовительные, "разогревочные" процессы, что добавляет времени.    
  ```
- Почему некоторые операции могут быть медленнее на GPU?
  ```
  В моих сравнениях это не проявилось, однако могу предположить, что передача данных между 
  CPU и GPU может являться узким местом, особенно это актуально для небольших данных, когда перенос данных
  туда-обратно может занять больше времени и ресурсов, чем выполнение операции.
  ```
- Как размер матриц влияет на ускорение?
  ```
  Из сравнительной таблицы видно, что в большинстве операций, особенно больших и трудоемких, меньшие по размеру
  матрицы получают меньшее ускорение, по сравнению с большими матрицами.
  ```
- Что происходит при передаче данных между CPU и GPU?
  ```
  1. Данные копируются из оперативной памяти компьютера (RAM) в видеопамять графического адаптера (VRAM).
  2. Затем GPU начинает выполнение вычислений.
  3. После завершения расчетов результат возвращается обратно в оперативную память RAM, 
  если требуется дальнейшая обработка на CPU.
  
  Передача данных создает задержку, особенно заметную при небольших объемах данных, что может 
  нивелировать преимущества GPU в простых задачах.
  ```

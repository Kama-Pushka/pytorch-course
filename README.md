# Домашнее задание к уроку 5: Аугментации и работа с изображениями

Примерное время выполнения: 4 часа.

---

## Задание 1: Стандартные аугментации torchvision (15 баллов)

- [x] Создайте пайплайн стандартных аугментаций torchvision (например, RandomHorizontalFlip, RandomCrop, ColorJitter, RandomRotation, RandomGrayscale).
- [x] Примените аугментации к 5 изображениям из разных классов (папка train).
- [x] Визуализируйте:
   - Оригинал
   - Результат применения каждой аугментации отдельно
   - Результат применения всех аугментаций вместе

---

Были использованы аугментации RandomHorizontalFlip, RandomCrop, ColorJitter, RandomRotation и RandomGrayscale.  
Скомпилированный график применения аугментаций к кажому классу датасета:

![1.png](plots%2F1.png)

## Задание 2: Кастомные аугментации (20 баллов)

- [x] Реализуйте минимум 3 кастомные аугментации (например, случайное размытие, случайная перспектива, случайная яркость/контрастность).
- [x] Примените их к изображениям из train.
- [x] Сравните визуально с готовыми аугментациями из extra_augs.py.

---

Были реализованы аугментации: случайное размытие, случайная перспектива и случайная яркость.
В график также были добавлены уже реализованные случайного шума, случайного стирания и вырезания. Остальные примеры [здесь](plots).

![2_Figure_1.png](plots%2F2_Figure_1.png)

## Задание 3: Анализ датасета (10 баллов)

1. Подсчитайте количество изображений в каждом классе.
2. Найдите минимальный, максимальный и средний размеры изображений.
3. Визуализируйте распределение размеров и гистограмму по классам.

---

```CommandLine
Средний размер изображений: (629.27, 545.64).
Минимальный размер изображений: (220, 210).
Максимальный размер изображений: (1308, 736).
```

![3_Figure_1.png](plots%2F3_Figure_1.png)
![3_Figure_2.png](plots%2F3_Figure_2.png)

Как видно из графиков, папки train и test содержат по 30 и 100 изображений соответственно, в каждом классе датасета по одинаковому количеству изображений.

Из графиков распределения заметно, что среднее значение высоты и ширины в обеих папках находится в районе 500-600px, что сходится с вычислениями.

## Задание 4: Pipeline аугментаций (20 баллов)

- [x] Реализуйте класс AugmentationPipeline с методами:
   - add_augmentation(name, aug)
   - remove_augmentation(name)
   - apply(image)
   - get_augmentations()
- [x] Создайте несколько конфигураций (light, medium, heavy).
- [x] Примените каждую конфигурацию к train и сохраните результаты.

---

Был создан класс AugmentationPipeline с требуемыми условиями, а также вспомогательные методы (random_horizontal_flip, random_rotation и т.д.), реализующие соответствующие аугментации.

Легкая конфигурация содержит аугментации преобразования к квадрату, отражения по горизонтали и случайного изменения яркости/контрастности с маленькими параметрами изменения.

В средней конфигурации к вышеописанным аугментациям добавляется случайное вращение, а параметры изменения яркости/контрастности увеличены.

В тяжелой конфигурации добавлен метод случайного зашумления, угол поворота увеличен, и увеличены параметры изменения яркости/контрастности.

С результатами можно ознакомится в папке [results](results).

## Задание 5: Эксперимент с размерами (10 баллов)

1. Проведите эксперимент с разными размерами изображений (например, 64x64, 128x128, 224x224, 512x512).
2. Для каждого размера измерьте время загрузки и применения аугментаций к 100 изображениям, а также потребление памяти.
3. Постройте графики зависимости времени и памяти от размера.

---

![5_Figure_1.png](plots%2F5_Figure_1.png)
![5_Figure_2.png](plots%2F5_Figure_2.png)

Из графиков видно, что загрузка небольших размеров (64x64, 128x128, 224x224) в среднем занимает примерно одинаковое время, загрузка больших размеров (512x512) будет занимать уже значительно больше времени.

Похожая история наболюдается и с памятью, однако на размере 224x224 на данном графике наблюдается заметный провал. Это может быть связано с работой сборщика мусора, либо ошибкой при вычислении объема занимаемой памяти.

## Задание 6: Дообучение предобученных моделей (25 баллов)

- [x] Возьмите одну из предобученных моделей torchvision (например, resnet18, efficientnet_b0, mobilenet_v3_small).
- [x] Замените последний слой на количество классов вашего датасета.
- [x] Дообучите модель на train, проверьте качество на val.
- [x] Визуализируйте процесс обучения (loss/accuracy).

---

Для обучения была выбрана модель resnet18.

![6_Figure_1.png](plots%2F6_Figure_1.png)

Данная модель показала себя не очень успешно, в ходе обучения заметна большая нестабильность модели. Это может говорить о том, что данная модель плохо подходит для обучения на нашем датасете.
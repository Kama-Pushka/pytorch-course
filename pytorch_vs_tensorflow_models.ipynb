{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLAclkMcSSLE",
        "outputId": "05b42882-f7a0-4a52-f7c1-a0092075af36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rahimanshu/cardiomegaly-disease-prediction-using-cnn?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 61.7M/61.7M [00:00<00:00, 78.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/rahimanshu/cardiomegaly-disease-prediction-using-cnn/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"rahimanshu/cardiomegaly-disease-prediction-using-cnn\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fuSZ0tIeCuK",
        "outputId": "33649b67-0ffe-4af3-bbef-9a234154b5d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.11/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from efficientnet_pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Loaded pretrained weights for efficientnet-b3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n",
            "torch.Size([16, 3, 300, 300]) torch.Size([16])\n",
            "Epoch 1/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5940, Train Accuracy: 0.6749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.5060, Validation Accuracy: 0.7558\n",
            "\n",
            "Epoch 2/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4169, Train Accuracy: 0.8164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.4496, Validation Accuracy: 0.7908\n",
            "\n",
            "Epoch 3/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2766, Train Accuracy: 0.8860\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.5658, Validation Accuracy: 0.7531\n",
            "\n",
            "Epoch 4/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1760, Train Accuracy: 0.9301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.6433, Validation Accuracy: 0.7810\n",
            "\n",
            "Epoch 5/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1211, Train Accuracy: 0.9527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.7682, Validation Accuracy: 0.7774\n",
            "\n",
            "Epoch 6/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0787, Train Accuracy: 0.9712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.6366, Validation Accuracy: 0.8070\n",
            "\n",
            "Epoch 7/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0577, Train Accuracy: 0.9813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.6540, Validation Accuracy: 0.8133\n",
            "\n",
            "Epoch 8/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0587, Train Accuracy: 0.9813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.6652, Validation Accuracy: 0.8061\n",
            "\n",
            "Epoch 9/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0565, Train Accuracy: 0.9826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.6552, Validation Accuracy: 0.8079\n",
            "\n",
            "Epoch 10/10:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0512, Train Accuracy: 0.9829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.6686, Validation Accuracy: 0.8079\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import EfficientNet_B5_Weights, EfficientNet_B3_Weights, EfficientNet_V2_S_Weights, \\\n",
        "    ResNet50_Weights, EfficientNet_B7_Weights, EfficientNet_B6_Weights\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize, RandomHorizontalFlip, RandomRotation\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torchvision\n",
        "!pip install efficientnet_pytorch\n",
        "!pip install torchinfo\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from torchinfo import summary\n",
        "\n",
        "### Датасет\n",
        "class CardiomegalyDataset(Dataset):\n",
        "    def __init__(self, data_dir: str, recursive=True):\n",
        "        \"\"\"\n",
        "        Инициализирует набор данных кардиомегалии с возможностью рекурсивного поиска классов.\n",
        "        :param data_dir: Основной путь к директории с изображениями ('train' or 'test')\n",
        "        :param recursive: Рекурсивно искать классы в подпапках (default: True)\n",
        "        \"\"\"\n",
        "        self.transform = EfficientNet_B3_Weights.IMAGENET1K_V1.transforms()\n",
        "\n",
        "        # Найдем все папки 'true' и 'false'\n",
        "        root_path = Path(data_dir)\n",
        "        if recursive: # Рекурсивно ищем папки 'true' и 'false'\n",
        "            true_folders = list(root_path.rglob(\"true\"))\n",
        "            false_folders = list(root_path.rglob(\"false\"))\n",
        "        else: # Если не рекурсивно, ограничимся первым уровнем вложенности\n",
        "            true_folders = [Path(root_path / \"true\")]\n",
        "            false_folders = [Path(root_path / \"false\")]\n",
        "\n",
        "        # Собираем полные пути к файлам и соответствующим меткам\n",
        "        paths_and_labels = []\n",
        "        for folder in true_folders:\n",
        "            files_in_true = sorted(folder.iterdir())\n",
        "            paths_and_labels.extend([(file, True) for file in files_in_true])\n",
        "\n",
        "        for folder in false_folders:\n",
        "            files_in_false = sorted(folder.iterdir())\n",
        "            paths_and_labels.extend([(file, False) for file in files_in_false])\n",
        "\n",
        "        self.paths_and_labels = paths_and_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths_and_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.paths_and_labels[idx]\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        transformed_img = self.transform(img)\n",
        "        target = torch.tensor(int(label))\n",
        "        return transformed_img, target\n",
        "\n",
        "def get_cardiomegaly_dataloaders(\n",
        "    train_data_path: str,\n",
        "    test_data_path: str,\n",
        "    batch_size: int = 16,\n",
        "    num_workers: int = 4,\n",
        "    shuffle_train: bool = True,\n",
        "    recursive: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Создаем загрузчики данных для тренировочных и тестовых данных, используя CardiomegalyDataset.\n",
        "    :param train_data_path: Путь к тренировочным данным\n",
        "    :param test_data_path: Путь к тестовым данным\n",
        "    :param batch_size: Размер батчей\n",
        "    :param num_workers: Число потоков для параллельной загрузки данных\n",
        "    :param shuffle_train: Нужно ли перемешивать тренировочные данные\n",
        "    :param recursive: Флаг, разрешающий рекурсивный поиск классов (по умолчанию включен)\n",
        "    :return: Кортеж (train_loader, test_loader) \"\"\"\n",
        "\n",
        "    train_dataset = CardiomegalyDataset(train_data_path, recursive=recursive)\n",
        "    test_dataset = CardiomegalyDataset(test_data_path, recursive=recursive)\n",
        "\n",
        "    # DataLoader для тренировок\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle_train,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    # DataLoader для тестов\n",
        "    test_loader = DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "### Модель\n",
        "class CardiomegalyClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.base_model = EfficientNet.from_pretrained('efficientnet-b3') # num_classes=2\n",
        "        self.head = nn.Sequential(\n",
        "            nn.BatchNorm1d(self.base_model._fc.in_features),\n",
        "            nn.Linear(self.base_model._fc.in_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, num_classes),\n",
        "            nn.LogSoftmax(dim=1)  # Логарифмическая Softmax для кросс-энтропии\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.base_model.extract_features(x) # Через EfficientNet получаем признаки\n",
        "        pooled_features = nn.functional.adaptive_max_pool2d(features, 1) # Применяем глобальный max pooling\n",
        "        flattened_features = pooled_features.view(pooled_features.size(0), -1)\n",
        "        output = self.head(flattened_features) # Прогоняем через головной слой\n",
        "        return output\n",
        "\n",
        "### Обучение\n",
        "def run_epoch(model, data_loader, loss_fn, optimizer=None, device=None, is_test=False):\n",
        "    \"\"\" Выполняет одну эпоху обучения или валидации.\n",
        "    :param model: Инстанс PyTorch модели\n",
        "    :param data_loader: DataLoader (для обучения или тестирования)\n",
        "    :param loss_fn: Критерий потерь (например, BCELoss)\n",
        "    :param optimizer: Оптимизатор (только для режима обучения)\n",
        "    :param device: Устройство (CPU/GPU)\n",
        "    :param is_test: Флаг, определяющий режим (training vs testing)\n",
        "    :return: Средняя потеря и точность за эпоху \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if is_test:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.set_grad_enabled(not is_test):\n",
        "        progress_bar = tqdm(data_loader, leave=False)\n",
        "        for inputs, labels in progress_bar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            if not is_test:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            outputs = model.forward(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            if not is_test:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() # * inputs.size(0)\n",
        "            pred = outputs.argmax(dim=1)\n",
        "            total_correct += (pred == labels).float().sum().item()\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            progress_bar.set_description(\n",
        "                f\"Loss: {total_loss / total_samples:.4f}, Acc: {total_correct / total_samples:.4f}\")\n",
        "\n",
        "    return total_loss / len(data_loader), total_correct / total_samples\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=10, lr=0.001, device=None, optimizer=None):\n",
        "    \"\"\" Управляет процессом обучения и периодической проверкой модели.\n",
        "    :param model: Инстанс PyTorch модели\n",
        "    :param train_loader: DataLoader для обучения\n",
        "    :param test_loader: DataLoader для тестирования\n",
        "    :param epochs: Количество эпох обучения\n",
        "    :param lr: Скорость обучения\n",
        "    :param device: Устройство (CPU/GPU)\n",
        "    :param optimizer: Пользовательский оптимизатор (опциональный)\n",
        "    :return: Словарь метрик обучения и тестирования \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if optimizer is None:\n",
        "        optimizer = torch.optim.Adamax(model.parameters(), lr=lr, weight_decay=0.0001) # Adam\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer,\n",
        "                                                  milestones=[int(epochs * 0.5), int(epochs * 0.75)], gamma=0.1,\n",
        "                                                  last_epoch=-1)\n",
        "    metrics = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "\n",
        "    best_test_loss = float('inf')\n",
        "    best_test_acc = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}:\")\n",
        "\n",
        "        train_loss, train_acc = run_epoch(model, train_loader, loss_fn, optimizer, device, is_test=False)\n",
        "        metrics[\"train_loss\"].append(train_loss)\n",
        "        metrics[\"train_acc\"].append(train_acc)\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "        val_loss, val_acc = run_epoch(model, test_loader, loss_fn, device=device, is_test=True)\n",
        "        metrics[\"val_loss\"].append(val_loss)\n",
        "        metrics[\"val_acc\"].append(val_acc)\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\\n\")\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    return metrics\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_data_path = '/root/.cache/kagglehub/datasets/rahimanshu/cardiomegaly-disease-prediction-using-cnn/versions/1/train/train'\n",
        "    test_data_path = '/root/.cache/kagglehub/datasets/rahimanshu/cardiomegaly-disease-prediction-using-cnn/versions/1/test/test'\n",
        "\n",
        "    model = CardiomegalyClassifier()\n",
        "    # model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=2)\n",
        "\n",
        "    train_loader, test_loader = get_cardiomegaly_dataloaders(train_data_path, test_data_path, recursive=False)\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        print(labels[:5])\n",
        "        print(inputs.shape, labels.shape)\n",
        "        summary(model, input_size=inputs.shape)\n",
        "        break\n",
        "\n",
        "    metrics = train_model(model, train_loader, test_loader, epochs=10, lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "WMM81_XmSLSf",
        "outputId": "05422dbd-0e58-4354-afe7-4ce645c90e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4438 validated image filenames belonging to 2 classes.\n",
            "Found 4438 validated image filenames belonging to 2 classes.\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
            "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">393,472</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb3 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │    \u001b[38;5;34m10,783,535\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │         \u001b[38;5;34m6,144\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m393,472\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m514\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,183,665</span> (42.66 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,183,665\u001b[0m (42.66 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,093,290</span> (42.32 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,093,290\u001b[0m (42.32 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,375</span> (353.03 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m90,375\u001b[0m (353.03 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 420ms/step - accuracy: 0.5679 - loss: 0.9052 - val_accuracy: 0.6848 - val_loss: 0.6249\n",
            "Epoch 2/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 178ms/step - accuracy: 0.7325 - loss: 0.5919 - val_accuracy: 0.8272 - val_loss: 0.3891\n",
            "Epoch 3/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 178ms/step - accuracy: 0.8093 - loss: 0.4146 - val_accuracy: 0.8914 - val_loss: 0.2603\n",
            "Epoch 4/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 217ms/step - accuracy: 0.8520 - loss: 0.3534 - val_accuracy: 0.9362 - val_loss: 0.1585\n",
            "Epoch 5/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 218ms/step - accuracy: 0.8858 - loss: 0.2700 - val_accuracy: 0.9691 - val_loss: 0.0901\n",
            "Epoch 6/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 181ms/step - accuracy: 0.9170 - loss: 0.2041 - val_accuracy: 0.9811 - val_loss: 0.0571\n",
            "Epoch 7/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 183ms/step - accuracy: 0.9484 - loss: 0.1401 - val_accuracy: 0.9944 - val_loss: 0.0264\n",
            "Epoch 8/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 183ms/step - accuracy: 0.9462 - loss: 0.1332 - val_accuracy: 0.9921 - val_loss: 0.0254\n",
            "Epoch 9/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 184ms/step - accuracy: 0.9526 - loss: 0.1061 - val_accuracy: 0.9957 - val_loss: 0.0205\n",
            "Epoch 10/10\n",
            "\u001b[1m278/278\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 181ms/step - accuracy: 0.9601 - loss: 0.0898 - val_accuracy: 0.9527 - val_loss: 0.1147\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D , MaxPooling2D , Flatten , Activation , Dense , Dropout , BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam , Adamax\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "### Датасет\n",
        "def get_data(data_path):\n",
        "  filepaths = []\n",
        "  labels = []\n",
        "\n",
        "  for fold in os.listdir(train_data_path):\n",
        "      f_path = os.path.join(train_data_path , fold)\n",
        "      filelists = os.listdir(f_path)\n",
        "      for file in filelists:\n",
        "          filepaths.append(os.path.join(f_path , file))\n",
        "          labels.append(fold)\n",
        "\n",
        "  return pd.concat([pd.Series(filepaths , name='filepaths') , pd.Series(labels , name='label')] , axis=1)\n",
        "\n",
        "train_data_path = '/root/.cache/kagglehub/datasets/rahimanshu/cardiomegaly-disease-prediction-using-cnn/versions/1/train/train'\n",
        "test_data_path = '/root/.cache/kagglehub/datasets/rahimanshu/cardiomegaly-disease-prediction-using-cnn/versions/1//test/test'\n",
        "\n",
        "train_df = get_data(train_data_path)\n",
        "test_df = get_data(test_data_path)\n",
        "\n",
        "img_size = (224,224)\n",
        "batch_size = 16\n",
        "\n",
        "train_loader = ImageDataGenerator().flow_from_dataframe(train_df,\n",
        "  x_col='filepaths',\n",
        "  y_col='label',\n",
        "  target_size=img_size,\n",
        "  class_mode='categorical',\n",
        "  color_mode='rgb',\n",
        "  shuffle=True,\n",
        "  batch_size=batch_size)\n",
        "\n",
        "\n",
        "test_loader = ImageDataGenerator().flow_from_dataframe(test_df,\n",
        "  x_col='filepaths',\n",
        "  y_col='label' ,\n",
        "  target_size=img_size,\n",
        "  class_mode='categorical',\n",
        "  color_mode='rgb',\n",
        "  shuffle=False ,\n",
        "  batch_size=batch_size)\n",
        "\n",
        "### Модель\n",
        "num_class = len(train_loader.class_indices)\n",
        "base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_shape=(img_size[0], img_size[1], 3), pooling='max')\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_class, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=Adamax(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "### Обучение\n",
        "history = model.fit(x=train_loader, epochs=10 , verbose=1 , validation_data=test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
